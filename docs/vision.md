# Техническое видение проекта HyperLiquid Node Parser

## Структура документа

1. **Технологии** - выбор технологического стека
2. **Принцип разработки** - подходы и методология
3. **Структура проекта** - организация файлов и папок
4. **Архитектура проекта** - компоненты и их взаимодействие
5. **Модель данных** - структуры данных и схемы
6. **Работа с нодой** - взаимодействие с HyperLiquid node
7. **Мониторинг новых логов** - отслеживание изменений
8. **Сценарии работы** - основные use cases
9. **Деплой** - развертывание приложения
10. **Подход к конфигурированию** - настройка приложения
11. **Подход к логгированию** - система логирования

## 1. Технологии

### Основной стек

**Backend:**
- **Python 3.11+** - основной язык разработки
- **FastAPI** - веб-фреймворк для создания API
- **Uvicorn** - ASGI сервер для запуска приложения

**Парсинг и обработка:**
- **re** (встроенный) - регулярные выражения для парсинга логов
- **json** (встроенный) - обработка JSON данных из логов

**Мониторинг файлов:**
- **watchdog** - отслеживание изменений в файлах логов

**Хранение данных:**
- **Файловое хранение** - JSON файлы для MVP (без БД)

**Дополнительные библиотеки:**
- **pydantic** - валидация данных (включен в FastAPI)
- **python-dotenv** - загрузка переменных окружения

### Принцип выбора
Минимальный стек для быстрой проверки идеи без оверинжиниринга.

## 2. Принцип разработки

### Основные принципы

- **KISS (Keep It Simple, Stupid)** - максимальная простота
- **MVP (Minimum Viable Product)** - только необходимый функционал
- **Fail Fast** - быстрая проверка идей
- **Single Responsibility** - каждый компонент делает одну вещь

### Подход к разработке

- **TDD (Test-Driven Development)** - обязательное написание тестов с самого начала
- **Итеративная разработка** - пошаговое добавление функционала
- **Прототипирование** - сначала простая версия, потом улучшения
- **Файловое хранение** - без сложных БД для MVP
- **Монолитная архитектура** - все в одном приложении

### Документирование кода

- **Минимум комментариев** - только самые необходимые
- **Docstrings для публичных методов** - обязательные описания
- **Приватные методы** - без документации
- **README и техническая документация** - минимально необходимые

### Методология

- **TDD** - сначала тест, потом код
- **Ручное тестирование** - для проверки интеграции
- **Конфигурация** - через переменные окружения и простые файлы

## 3. Структура проекта

```
hyperliquid-parser/
├── src/
│   ├── __init__.py
│   ├── main.py              # точка входа FastAPI
│   ├── parser/              # модуль парсинга логов
│   │   ├── __init__.py
│   │   ├── log_parser.py    # парсер логов
│   │   └── order_extractor.py # извлечение данных об ордерах
│   ├── api/                 # API endpoints
│   │   ├── __init__.py
│   │   └── routes.py        # маршруты API
│   ├── storage/             # хранение данных
│   │   ├── __init__.py
│   │   └── file_storage.py  # файловое хранение
│   └── watcher/             # мониторинг файлов
│       ├── __init__.py
│       └── file_watcher.py  # отслеживание изменений
├── tests/                   # тесты
│   ├── __init__.py
│   ├── test_parser.py
│   ├── test_api.py
│   └── test_storage.py
├── data/                    # данные
│   ├── logs/               # логи ноды (для тестов)
│   └── orders.json         # извлеченные данные
├── config/                  # конфигурация
│   └── settings.py         # настройки приложения
├── requirements.txt         # зависимости
├── .env.example            # пример переменных окружения
├── README.md               # документация
└── run.py                  # скрипт запуска
```

### Принципы организации

- **Модульная структура** - каждый компонент в отдельной папке
- **Простота навигации** - понятные имена файлов и папок
- **Разделение ответственности** - парсинг, API, хранение, мониторинг
- **Готовность к тестированию** - отдельная папка для тестов

## 4. Архитектура проекта

### Основные компоненты

1. **API Layer (FastAPI)** - веб-интерфейс и endpoints
2. **Parser Module** - парсинг логов и извлечение данных
3. **Storage Module** - файловое хранение данных
4. **Watcher Module** - мониторинг изменений в логах
5. **Config Module** - управление настройками

### Взаимодействие компонентов

```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   Watcher   │───▶│   Parser    │───▶│   Storage   │
│  (watchdog) │    │ (log_parser)│    │(file_storage)│
└─────────────┘    └─────────────┘    └─────────────┘
                           │                   ▲
                           ▼                   │
                    ┌─────────────┐            │
                    │     API     │────────────┘
                    │  (FastAPI)  │
                    └─────────────┘
                           ▲
                           │
                    ┌─────────────┐
                    │   Config    │
                    │ (settings)  │
                    └─────────────┘
```

### Поток данных

1. **Watcher** отслеживает изменения в логах (асинхронно)
2. **Parser** обрабатывает новые записи (асинхронно)
3. **Storage** сохраняет извлеченные данные (асинхронно)
4. **API** предоставляет доступ к данным (асинхронно)

### Асинхронность

- **FastAPI** - встроенная асинхронность для API
- **Watcher** - асинхронное отслеживание файлов
- **Parser** - асинхронная обработка логов
- **Storage** - асинхронные операции записи/чтения
- **Event-driven** - компоненты общаются через события

## 5. Модель данных

### Основные модели

1. **Order** - данные об ордере
2. **LogEntry** - запись из лога
3. **ParsedData** - результат парсинга

### Структуры данных

```python
# Order - данные об ордере
{
    "id": "unique_order_id",
    "symbol": "BTC-PERP",
    "side": "buy|sell",
    "price": 50000.0,
    "size": 1.5,
    "owner": "0x1234567890abcdef...",  # адрес кошелька владельца
    "timestamp": "2024-01-01T12:00:00Z",
    "status": "open|filled|cancelled"
}

# LogEntry - запись из лога
{
    "timestamp": "2024-01-01T12:00:00Z",
    "level": "INFO|ERROR|DEBUG",
    "class": "OrderBook|NodeManager|Validator",  # класс, где была сделана запись
    "message": "raw log message",
    "raw_data": "original log line"
}

# ParsedData - результат парсинга
{
    "orders": [Order],
    "metadata": {
        "parsed_at": "2024-01-01T12:00:00Z",
        "source_file": "node.log",
        "total_orders": 10
    }
}
```

### Формат хранения

- **JSON** - основной формат для всех данных
- **Файловая структура** - один файл для всех ордеров
- **Метаданные** - включены в структуру данных

### Принципы моделирования

- **Простота** - минимально необходимые поля
- **Расширяемость** - возможность добавления новых полей
- **Валидация** - проверка типов данных через Pydantic

## 6. Работа с нодой

### Источники данных

1. **Файлы логов** - основной источник
2. **API ноды** - опционально, если доступен

### Структура логов ноды

**Путь к данным:**
```
~/hl/data/node_raw_book_diffs/hourly/{date}/{hour}
```

**Формат данных (JSON):**
```json
// Новый ордер
{
  "user": "0x768484f7e2ebb675c57838366c02ae99ba2a9b08",
  "oid": 35061046831,
  "coin": "CHILLGUY",
  "side": "Bid",
  "px": "1.36",
  "raw_book_diff": {
    "new": {"sz": "186910.0"}
  }
}

// Обновление ордера
{
  "user": "0x768484f7e2ebb675c57838366c02ae99ba2a9b08",
  "oid": 35061055064,
  "coin": "BTC",
  "side": "Bid",
  "px": "115323.2",
  "raw_book_diff": {
    "update": {"origSz": "0.2086", "newSz": "0.2076"}
  }
}

// Удаление ордера
{
  "user": "0xc64cc00b46101bd40aa1c3121195e85c0b0918d8",
  "oid": 35061057543,
  "side": "Ask",
  "px": "115200.2",
  "coin": "HYPE",
  "raw_book_diff": "remove"
}
```

### Типы операций

- **new** - новый ордер
- **update** - обновление размера ордера
- **remove** - удаление ордера

### Конфигурация

- **Путь к логам** - настраивается через переменные окружения
- **Поиск файлов** - автоматический поиск по паттерну даты/часа
- **API ноды** - опциональный источник данных

### Обработка ошибок

- **Файл не найден** - логирование ошибки
- **Нет прав доступа** - уведомление пользователя
- **Поврежденный JSON** - пропуск проблемных строк
- **Неизвестный формат** - логирование для анализа

## 7. Мониторинг новых логов

### Стратегия мониторинга

1. **Watchdog** - отслеживание изменений в папке с логами
2. **Периодическое сканирование** - как fallback
3. **Обработка новых и существующих файлов** - автоматический парсинг

### Логика работы

**Отслеживание папки:**
- **Путь** - `~/hl/data/node_raw_book_diffs/hourly/`
- **Фильтрация** - только JSON файлы
- **События** - создание, изменение, удаление файлов
- **Асинхронная обработка** - без блокировки основного потока

**При запуске:**
- **Сканирование последнего файла** - только самый свежий файл
- **Определение последнего файла** - по времени модификации
- **Парсинг существующих данных** - для восстановления состояния

**Периодическая очистка:**
- **Удаление старых данных** - файлы старше 2 часов
- **Очистка ордеров** - удаление неактуальных записей
- **Настраиваемый интервал** - через конфигурацию

### Конфигурация

- **Путь к логам** - `NODE_LOGS_PATH`
- **Интервал очистки** - `CLEANUP_INTERVAL_HOURS` (по умолчанию 2)
- **Частота сканирования** - `SCAN_INTERVAL_SECONDS` (fallback)

### Обработка событий

- **Новый файл** - немедленный парсинг
- **Изменение файла** - перепарсинг с учетом изменений
- **Удаление файла** - очистка соответствующих данных
- **Ошибки доступа** - логирование и повторные попытки

## 8. Сценарии работы

### Основные сценарии

1. **Запуск приложения** - инициализация и сканирование последнего файла
2. **Мониторинг новых данных** - обработка изменений в реальном времени
3. **Запрос данных через API** - получение информации об ордерах
4. **Периодическая очистка** - удаление устаревших данных
5. **Управление конфигурацией** - настройка монет и параметров

### Детальные сценарии

**Сценарий 1: Запуск**
- Приложение стартует
- Сканирует последний файл логов
- Восстанавливает состояние ордеров
- Запускает мониторинг изменений

**Сценарий 2: Новые данные**
- Обнаружен новый файл логов
- Парсер извлекает данные об ордерах
- Storage сохраняет новые записи
- API готов предоставить актуальные данные

**Сценарий 3: Запрос данных через API**
- Фильтрация по символу (coin)
- Фильтрация по направлению (side: Bid/Ask)
- Фильтрация по цене с точностью ±epsilon
- Фильтрация по минимальному объему ликвидности (price * size)
- Возврат только открытых ордеров (status: open)

**Сценарий 4: Управление статусами ордеров**
- **Граф состояний:**
  - `open` → `filled`
  - `open` → `cancelled`
  - `open` → `triggered` → `filled`
  - `open` → `triggered` → `cancelled`
- **Обработка неизвестных статусов:**
  - Если ордер в `open`/`triggered` → `cancelled`
  - Если ордер не существует или в `filled`/`cancelled` → `cancelled`
  - Логирование реального статуса из ноды

**Сценарий 5: Управление конфигурацией**
- Чтение настроек из JSON файла
- Настройка минимального объема ликвидности по монетам
- Управление списком поддерживаемых монет
- Изменение конфигурации через API

### API Endpoints

**GET /orders**
- Параметры: `symbol`, `side`, `price`, `min_liquidity`
- Возврат: список открытых ордеров
- Фильтрация по объему ликвидности

**GET /config**
- Возврат: текущая конфигурация монет

**PUT /config**
- Обновление конфигурации монет

### Конфигурация монет

```json
{
  "coins": {
    "BTC": {
      "min_liquidity": 1000.0,
      "price_precision": 0.1
    },
    "ETH": {
      "min_liquidity": 500.0,
      "price_precision": 0.01
    }
  },
  "default_min_liquidity": 100.0,
  "default_price_precision": 0.001
}
```

### Ограничения

- **Пагинация** - не требуется на первых этапах
- **Объем данных** - ограничен для API
- **Точность цены** - настраиваемая для каждой монеты
- **Минимальная ликвидность** - настраиваемая по монетам

## 9. Деплой

### Способы деплоя

1. **Локальный запуск** - для разработки и тестирования
2. **Docker контейнер** - основной способ для продакшена
3. **GitHub Actions** - автоматический деплой

### Локальный запуск

**Для разработки:**
```bash
python run.py
# или
uvicorn src.main:app --reload
```

### Docker

**Dockerfile:**
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Docker Compose:**
```yaml
version: '3.8'
services:
  hyperliquid-parser:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ~/hl/data:/hl/data:ro
    environment:
      - NODE_LOGS_PATH=/hl/data/node_raw_book_diffs/hourly
    restart: unless-stopped
```

### Автоматический деплой

**GitHub Actions (.github/workflows/deploy.yml):**
```yaml
name: Deploy to Ubuntu

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Deploy to server
        uses: appleboy/ssh-action@v0.1.5
        with:
          host: ${{ secrets.HOST }}
          username: ${{ secrets.USERNAME }}
          key: ${{ secrets.SSH_KEY }}
          script: |
            cd /opt/hyperliquid-parser
            git pull origin main
            docker-compose down
            docker-compose up -d --build
```

### Ubuntu развертывание

**Структура на сервере:**
```
/opt/hyperliquid-parser/
├── docker-compose.yml
├── .env
├── data/
└── logs/
```

**Systemd сервис (опционально):**
```ini
[Unit]
Description=HyperLiquid Parser
After=docker.service

[Service]
Type=oneshot
RemainAfterExit=yes
WorkingDirectory=/opt/hyperliquid-parser
ExecStart=/usr/local/bin/docker-compose up -d
ExecStop=/usr/local/bin/docker-compose down

[Install]
WantedBy=multi-user.target
```

### Переменные окружения

**Пример .env:**
```env
NODE_LOGS_PATH=~/hl/data/node_raw_book_diffs/hourly
CLEANUP_INTERVAL_HOURS=2
SCAN_INTERVAL_SECONDS=30
API_HOST=0.0.0.0
API_PORT=8000
```

### Мониторинг

- **Логи контейнера** - `docker-compose logs -f`
- **Статус сервиса** - `docker-compose ps`
- **Метрики** - через API endpoints

## 10. Подход к конфигурированию

### Уровни конфигурации

1. **Переменные окружения** - основные настройки
2. **JSON файлы** - конфигурация монет и параметров
3. **API** - динамическое изменение настроек

### Переменные окружения

**Основные настройки:**
- `NODE_LOGS_PATH` - путь к логам ноды
- `CLEANUP_INTERVAL_HOURS` - интервал очистки (по умолчанию 2)
- `SCAN_INTERVAL_SECONDS` - частота сканирования (fallback)
- `API_HOST` - хост API сервера (по умолчанию 0.0.0.0)
- `API_PORT` - порт API сервера (по умолчанию 8000)
- `LOG_LEVEL` - уровень логирования (INFO, DEBUG, ERROR)

**Дополнительные настройки:**
- `CONFIG_FILE_PATH` - путь к файлу конфигурации монет
- `DATA_DIR` - директория для хранения данных
- `MAX_ORDERS_PER_REQUEST` - максимальное количество ордеров в ответе

### JSON конфигурация

**Файл конфигурации монет:**
```json
{
  "coins": {
    "BTC": {
      "min_liquidity": 1000.0,
      "price_precision": 0.1,
      "enabled": true
    },
    "ETH": {
      "min_liquidity": 500.0,
      "price_precision": 0.01,
      "enabled": true
    }
  },
  "defaults": {
    "min_liquidity": 100.0,
    "price_precision": 0.001,
    "enabled": true
  },
  "api": {
    "max_orders_per_request": 1000,
    "default_timeout": 30
  }
}
```

### Валидация конфигурации

**Проверка переменных окружения:**
- Обязательные переменные при запуске
- Валидация типов данных
- Проверка диапазонов значений

**Проверка JSON конфигурации:**
- Валидация схемы через Pydantic
- Проверка обязательных полей
- Валидация значений (положительные числа, корректные диапазоны)

**Обработка ошибок:**
- Логирование ошибок валидации
- Использование значений по умолчанию
- Graceful degradation при некорректной конфигурации

### Динамическое изменение

**API endpoints для конфигурации:**
- `GET /config` - получение текущей конфигурации
- `PUT /config` - обновление конфигурации
- `POST /config/reload` - перезагрузка конфигурации из файла

**Безопасность:**
- Валидация входящих данных
- Проверка прав доступа (если требуется)
- Backup конфигурации перед изменением

## 11. Подход к логгированию

### Уровни логирования

- **DEBUG** - детальная информация для разработки (по умолчанию)
- **INFO** - общая информация о работе приложения
- **WARNING** - предупреждения, не критичные ошибки
- **ERROR** - ошибки, требующие внимания
- **CRITICAL** - критические ошибки

### Структура логов

**Формат записи:**
```
2024-01-01T12:00:00.123Z [DEBUG] [parser] Парсинг файла node.log
2024-01-01T12:00:01.456Z [INFO] [storage] Сохранено 10 ордеров
2024-01-01T12:00:02.789Z [ERROR] [watcher] Ошибка доступа к файлу
```

**Компоненты:**
- **Временная метка** - ISO формат с миллисекундами
- **Уровень** - DEBUG, INFO, WARNING, ERROR, CRITICAL
- **Модуль** - название компонента (parser, storage, watcher, api)
- **Сообщение** - описание события

### Управление файлами логов

**Именование файлов:**
```
logs/hyperliquid-parser-2024-01-01-12-00-00.log
logs/hyperliquid-parser-2024-01-01-13-00-00.log
```

**Ограничения:**
- **Максимальный размер** - 100 МБ на файл
- **Ротация** - автоматическая при достижении лимита
- **Метка времени** - в имени файла для уникальности

**Очистка старых логов:**
- **Период хранения** - настраивается (по умолчанию 30 дней)
- **Автоматическое удаление** - старые файлы логов
- **Конфигурация** - через переменную окружения

### Конфигурация логирования

**Переменные окружения:**
```env
LOG_LEVEL=DEBUG                    # уровень логирования
LOG_FILE_PATH=logs/app.log         # путь к файлу логов
LOG_MAX_SIZE_MB=100               # максимальный размер файла
LOG_RETENTION_DAYS=30             # период хранения логов
LOG_FORMAT=detailed               # формат логов (simple/detailed)
```

**Настройки по умолчанию:**
- **Уровень** - DEBUG (для разработки)
- **Размер файла** - 100 МБ
- **Период хранения** - 30 дней
- **Формат** - детальный с временными метками

### Централизованное логирование

**Единый файл для всех модулей:**
- Все компоненты пишут в один файл
- Структурированный формат
- Легкий поиск и анализ

**Контекстная информация:**
- Имя модуля в каждой записи
- Дополнительные метаданные при необходимости
- Трейсинг операций через correlation ID

### Мониторинг логов

**Метрики:**
- Количество записей по уровням
- Размер файлов логов
- Частота ротации

**Алерты:**
- Превышение размера файла
- Высокая частота ошибок
- Отсутствие новых записей

---

## Заключение

Данный документ представляет техническое видение проекта HyperLiquid Node Parser - простого и эффективного решения для парсинга логов ноды и предоставления данных об ордерах через API.

**Ключевые принципы:**
- Минимализм и простота (KISS)
- Быстрая проверка идеи (MVP)
- Асинхронная архитектура
- TDD подход к разработке
- Готовность к масштабированию

**Следующие шаги:**
1. Создание базовой структуры проекта
2. Реализация основных компонентов
3. Написание тестов
4. Интеграционное тестирование
5. Деплой и мониторинг

*Документ завершен*
